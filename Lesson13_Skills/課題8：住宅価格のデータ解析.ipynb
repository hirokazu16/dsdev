{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf8l32CBx91l"
      },
      "source": [
        "# 課題8：住宅価格のデータ解析"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APrhOmlhyQjl"
      },
      "source": [
        "課題6では、アイオワ州の住宅価格予測を行ないました。その際に利用したデータは、モデリングの基礎を学びやすくするために、変数の抜粋やデータの調整を施していました。\n",
        "\n",
        "では、調整されていない「実際のデータ」を使って解析するには、どうしたらよいでしょうか？アイオワ州の住宅価格のデータは有名であるため、さまざまな人がブログなどで、その方法を公開しています。\n",
        "\n",
        "例: https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
        "\n",
        "本課題では、*iowa_housing_price.csv* のデータを使って作業に取り組んでもらいます。課題を通じて「実際のデータを使って解析する際にどのような作業を行なうか」について学び、今までの知識をブラッシュアップしていきましょう。\n",
        "\n",
        "CSVの各列がどういう情報かについては、以下のページの Data fields を参照してください。\n",
        "\n",
        "https://www.openintro.org/data/index.php?data=ames\n",
        "\n",
        "**注意点：**\n",
        "\n",
        "- 列名にドット（`.`）が入っているとPandasの処理中にエラーが発生するため、元データの列名から `.` を削除しています\n",
        "- PID列のみ、元データから削除しています"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvZGAxy2yXul"
      },
      "source": [
        "## 1. 必要なライブラリの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gg_UVTY4ybtU"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリの読み込み（変更しないでください）\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLKPU27RypnP"
      },
      "source": [
        "## 2. データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meMeZZlbyW2U"
      },
      "outputs": [],
      "source": [
        "# CSVファイルからデータを読み込んで変数 data に格納\n",
        "# （列数が非常に多いため、head()などは使わずファイル一覧からCSVを開いて確認してください）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlRFVUNvZce5"
      },
      "source": [
        "## 3. データの概要を確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4c5bmscZfxj"
      },
      "source": [
        "データの正規性をQ-Qプロットで確認します。正規性が小さいと、検定の種類によっては結果を正しく解析することができないからです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kyef59Rxvkh"
      },
      "outputs": [],
      "source": [
        "# priceについてQ-Qプロットを確認\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIsTDmXBaE-T"
      },
      "source": [
        "直線にあまり乗っていません。このような場合は、何らかの **データ変換** を行い、正規性が確保できる状態にします。今回は **Log Transformation（対数変換）** を実施しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yhPW_1iyCQH"
      },
      "outputs": [],
      "source": [
        "# NumPy の log1p を用いて、すべてのデータのprice列を対数変換\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKnvtbhAyIU5"
      },
      "outputs": [],
      "source": [
        "# 再度priceについてQ-Qプロットを確認\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnAGmFwsaYUF"
      },
      "source": [
        "## 4. 欠損値の確認と補充\n",
        "\n",
        "データが欠損値を含む場合、そのまま回帰分析等を行うとエラーが発生したり、精度が悪くなる可能性があります。\n",
        "\n",
        "欠損値があまり多くない場合には、シンプルに欠損値を含むデータを削除すればよいです。\n",
        "しかし、欠損値が多い場合には削除してしまうとデータの多くを失ってしまうことになります。\n",
        "そのような場合には、**当たり障りのない値で埋める** という手法が取られます。\n",
        "\n",
        "まずは欠損値を含む列について、その数を出力してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaqLPay_N9f"
      },
      "outputs": [],
      "source": [
        "# 欠損値の数を調べる\n",
        "# （1つ以上の欠損値がある列の情報のみ表示すること）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH2-6Y4Xa36L"
      },
      "source": [
        "次に、欠損値の補充を行います。本来ならすべての列について欠損値を埋めるべきですが、今回の課題では2つの列についてのみ対応します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY3NTazGa75U"
      },
      "source": [
        "### 4-1. PoolQCの場合\n",
        "\n",
        "PoolQCは「プールの品質」に関する情報です。プールがない家は NaN（csv上では NA ）が入っています。そのため、「無いことを意味しているが欠損値として扱われないデータ」、たとえば \"None\" という文字列で置き換えましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca5lWZN5_raD"
      },
      "outputs": [],
      "source": [
        "# PoolQCの欠損値を文字列 \"None\" で置換する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcP7Ev2EbM3h"
      },
      "source": [
        "### 4-2. LotFrontageの場合\n",
        "\n",
        "LotFrontageは「間口の広さ（家屋の正面の幅）」に関する情報です。LotFrontageが欠損している場合、どのような値を埋めれば良いかを考えます。一例としては「近隣の家々」、つまり、**近くの通りの名前（Neighborhood）が同じ家々のLotFrontageの値とほぼ同じにする**、という考え方です。\n",
        "\n",
        "そこで今回は、補充する値として「Neighborhoodが同じ家々のLotFrontageの中央値（median）」を採用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFTLFJe__-fY"
      },
      "outputs": [],
      "source": [
        "# Neighborhoodが同じ情報でグループ化して、各グループのLotFrontageの中央値を求める\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUaZHknNBD6S"
      },
      "outputs": [],
      "source": [
        "# LotFrontageの欠損値をNeighborhoodのグループごとの中央値で埋める\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlsMq6vZbj7Q"
      },
      "source": [
        "## 5. 変数の選択\n",
        "\n",
        "相関関係のある変数を複数、モデルに含めてしまうと、回帰係数の分散が大きくなりモデルが不安定になります。この問題を **多重共線性** と言います。\n",
        "\n",
        "多重共線性を回避するためには、あらかじめ変数同士の相関について確認し、強い相関関係にあるものは取り除く必要があります。ここではその方法について確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtJkpQXgCKza"
      },
      "outputs": [],
      "source": [
        "# 相関係数が threshold に設定した数値以上だった場合、その変数を取り除く\n",
        "# （今回はしきい値を0.8で設定）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmRuciZLCSZJ"
      },
      "outputs": [],
      "source": [
        "# data から相関行列（Correlation Matrix）を作成する。\n",
        "# （絶対値を適用して負の値をプラスに変換すること）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhH3xOKyCu3w"
      },
      "outputs": [],
      "source": [
        "# 相関行列を上三角行列に変換\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1ld_DjfDV3R"
      },
      "outputs": [],
      "source": [
        "# 上三角行列から price以外の列について threshold 以上の値が1つ以上ある列を抽出。\n",
        "# その「削除すべき変数」の名前および総数を表示する（→これを除去すべき変数と判断します）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8E9hCjbT2rM"
      },
      "outputs": [],
      "source": [
        "# # data から削除する変数を削除して data_dropped に格納する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnX5ypbccQAF"
      },
      "source": [
        "## 6. ダミー変数化\n",
        "\n",
        "カテゴリ変数は **ダミー変数化** する必要があります。\n",
        "\n",
        "ひとつ例を出して説明します。たとえば、「Weather」という列があり、そこに入っているデータが、以下の3種類の文字列のみで構成されているとします。\n",
        "\n",
        "- 'Sunny'（晴れ）\n",
        "- 'Cloudy'（くもり）\n",
        "- 'Rainy'（雨）\n",
        "\n",
        "このとき「Weather」を、以下のような内容の3つの列に分割します。\n",
        "\n",
        "- Weather_Sunny: 元の Weather のデータが 'Sunny' なら整数値の 1 が、それ以外なら整数値の 0 が入る\n",
        "- Weather_Cloudy: 元の Weather のデータが 'Cloudy' なら整数値の 1 が、それ以外なら整数値の 0 が入る\n",
        "- Weather_Rainy: 元の Weather のデータが 'Rainy' なら整数値の 1 が、それ以外なら整数値の 0 が入る\n",
        "\n",
        "このような作業がダミー変数化です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7BG39F2UHnA"
      },
      "outputs": [],
      "source": [
        "# data_dropped に含まれる全てのカテゴリ変数をダミー変数化して data_dummied に格納する。\n",
        "# ダミー変数化には Pandas の関数を実行すること。\n",
        "# （ひとつずつダミー変数化しても良いですが、ここでは一気にすべてダミー変数化する命令を使います）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuXPAOW1c2um"
      },
      "source": [
        "読み込んだデータに対して「データの対数変換」「欠損値の補充」「多重共線性の回避」「ダミー変数化」の作業を行いました。このような作業を通したデータを分類や予測にかけると、精度の良い結果が得られます。\n",
        "\n",
        "本課題としての必須項目は、ここまでです。お疲れ様でした！\n",
        "\n",
        "課題に合格後、もし余裕がある場合は、最初に挙げたKaggle上の解説ページなどを参考に、課題では行なわなかった他の列の欠損値を自分なりに考えて埋めてみたり、Ridge回帰したりなどしてみてください。\n",
        "（ただし任意の学習内容となるため、Slackでのサポートは対象外とさせていただきます）"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
